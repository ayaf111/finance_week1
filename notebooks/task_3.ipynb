{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a8fe6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the directory containing your CSV files\n",
    "folder_path = \"../yfinance_data/the file\"  # Make sure this path is correct\n",
    "\n",
    "# Dictionary to hold individual DataFrames\n",
    "data_dict = {}\n",
    "\n",
    "# Loop through all CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        stock_name = filename.replace(\".csv\", \"\")\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Load CSV into DataFrame with datetime index\n",
    "        df = pd.read_csv(file_path, parse_dates=True, index_col=0)\n",
    "        \n",
    "        # Ensure index is datetime and add normalized date\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df['Date'] = df.index.normalize()\n",
    "        \n",
    "        # Save to dictionary\n",
    "        data_dict[stock_name] = df\n",
    "   # Create a new column with just the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4b89d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_18028\\4162999943.py:4: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  news_df['date'] = pd.to_datetime(news_df['date'], errors='coerce', infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns, UTC-04:00]\n",
      "0   2020-06-05 10:30:54-04:00\n",
      "1   2020-06-03 10:45:20-04:00\n",
      "2   2020-05-26 04:30:07-04:00\n",
      "3   2020-05-22 12:45:06-04:00\n",
      "4   2020-05-22 11:38:59-04:00\n",
      "Name: date, dtype: datetime64[ns, UTC-04:00]\n"
     ]
    }
   ],
   "source": [
    "# For news data\n",
    "news_df=pd.read_csv(\"C:/Users/Student/Documents/kaim documents/week 1/raw_analyst_ratings.csv/raw_analyst_ratings.csv\")\n",
    "# Step 1: Convert to datetime (safely)\n",
    "news_df['date'] = pd.to_datetime(news_df['date'], errors='coerce', infer_datetime_format=True)\n",
    "print(news_df['date'].dtype)\n",
    "print(news_df['date'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78dcaa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_18028\\2068501246.py:3: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  news_df['date'] = pd.to_datetime(news_df['date'], errors='coerce', infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns, UTC-04:00]\n",
      "0   2020-06-05 10:30:54-04:00\n",
      "1   2020-06-03 10:45:20-04:00\n",
      "2   2020-05-26 04:30:07-04:00\n",
      "3   2020-05-22 12:45:06-04:00\n",
      "4   2020-05-22 11:38:59-04:00\n",
      "Name: date, dtype: datetime64[ns, UTC-04:00]\n",
      "0   2020-06-05\n",
      "1   2020-06-03\n",
      "2   2020-05-26\n",
      "3   2020-05-22\n",
      "4   2020-05-22\n",
      "Name: date, dtype: datetime64[ns]\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "news_df = pd.read_csv(\"C:/Users/Student/Documents/kaim documents/week 1/raw_analyst_ratings.csv/raw_analyst_ratings.csv\")\n",
    "\n",
    "news_df['date'] = pd.to_datetime(news_df['date'], errors='coerce', infer_datetime_format=True)\n",
    "\n",
    "print(news_df['date'].dtype)\n",
    "print(news_df['date'].head())\n",
    "\n",
    "news_df = news_df.dropna(subset=['date'])  # Drop NaT values\n",
    "\n",
    "# Remove timezone to avoid errors with .dt.normalize()\n",
    "news_df['date'] = news_df['date'].dt.tz_localize(None)\n",
    "\n",
    "# Normalize date to midnight\n",
    "news_df['date'] = news_df['date'].dt.normalize()\n",
    "news_df = news_df.dropna(subset=['date'])\n",
    "\n",
    "print(news_df['date'].head())\n",
    "print(news_df['date'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e92816b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import time\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58668f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load your datasets\n",
    "def load_data():\n",
    "    \"\"\"Load news and stock data from your specific paths\"\"\"\n",
    "    # Load news data\n",
    "    news_df = pd.read_csv(\"C:/Users/Student/Documents/kaim documents/week 1/raw_analyst_ratings.csv/raw_analyst_ratings.csv\")\n",
    "    \n",
    "    # Load stock data from multiple files\n",
    "    folder_path = \"../yfinance_data/the file\"\n",
    "    data_dict = {}\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            stock_name = filename.replace(\".csv\", \"\")\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            data_dict[stock_name] = pd.read_csv(file_path, parse_dates=True, index_col=0)\n",
    "    \n",
    "    return news_df, data_dict\n",
    "news_df, data_dict = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a5b20e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close  Adj Close     Volume  \\\n",
      "Date                                                                       \n",
      "1980-12-12  0.128348  0.128906  0.128348  0.128348   0.098943  469033600   \n",
      "1980-12-15  0.122210  0.122210  0.121652  0.121652   0.093781  175884800   \n",
      "1980-12-16  0.113281  0.113281  0.112723  0.112723   0.086898  105728000   \n",
      "1980-12-17  0.115513  0.116071  0.115513  0.115513   0.089049   86441600   \n",
      "1980-12-18  0.118862  0.119420  0.118862  0.118862   0.091630   73449600   \n",
      "\n",
      "            Dividends  Stock Splits                Ticker  \n",
      "Date                                                       \n",
      "1980-12-12        0.0           0.0  AAPL_historical_data  \n",
      "1980-12-15        0.0           0.0  AAPL_historical_data  \n",
      "1980-12-16        0.0           0.0  AAPL_historical_data  \n",
      "1980-12-17        0.0           0.0  AAPL_historical_data  \n",
      "1980-12-18        0.0           0.0  AAPL_historical_data  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends',\n",
      "       'Stock Splits', 'Ticker'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 2. Preprocess and align data\n",
    "def preprocess_data(news_df, data_dict):\n",
    "    \"\"\"Clean and prepare data for analysis\"\"\"\n",
    "    # Convert news timestamp to datetime\n",
    "    news_df = news_df.copy()\n",
    "    news_df['date'] = pd.to_datetime(news_df['date'], errors='coerce')\n",
    "    news_df =news_df.dropna(subset=['date'])  # Remove rows where conversion failed\n",
    "    news_df['date'] =news_df['date'].dt.normalize().dt.tz_localize(None)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Create a combined stock DataFrame with ticker information\n",
    "    stock_dfs = []\n",
    "    for ticker, df in data_dict.items():\n",
    "        temp_df = df.copy()\n",
    "        temp_df['Ticker'] = ticker\n",
    "        stock_dfs.append(temp_df)\n",
    "    \n",
    "    combined_stocks=pd.concat(stock_dfs)\n",
    "    combined_stocks.index = pd.to_datetime(combined_stocks.index)\n",
    "\n",
    "    return news_df, combined_stocks\n",
    "# Call the function and store the result\n",
    "\n",
    "# Now preprocess and align the data\n",
    "clean_news_df, combined_stocks_df = preprocess_data(news_df, data_dict)\n",
    "\n",
    "# Check the results\n",
    "print(combined_stocks_df.head())\n",
    "print(combined_stocks_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6625ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "0   2020-06-05\n",
      "1   2020-06-03\n",
      "2   2020-05-26\n",
      "3   2020-05-22\n",
      "4   2020-05-22\n",
      "Name: date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Parse datetime with timezone info\n",
    "news_df['date'] = pd.to_datetime(news_df['date'], errors='coerce')\n",
    "\n",
    "# Convert to timezone naive (optional)\n",
    "news_df['date'] = news_df['date'].dt.tz_localize(None)\n",
    "\n",
    "# Normalize to remove time (keep date only)\n",
    "news_df['date'] = news_df['date'].dt.normalize()\n",
    "\n",
    "print(news_df['date'].dtype)\n",
    "print(news_df['date'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ae41e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock',\n",
      "       'trading_day'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from datetime import time\n",
    "import pandas as pd\n",
    "\n",
    "def align_news_with_stocks(news_df, combined_stocks_df):\n",
    "    \"\"\"Assign each news article to a valid trading day in the stock data.\"\"\"\n",
    "    \n",
    "    # Define market open and close times\n",
    "    MARKET_OPEN = time(9, 30)\n",
    "    MARKET_CLOSE = time(16, 0)\n",
    "\n",
    "    # Get unique trading days (dates only) from stock_dfs index\n",
    "    trading_days = combined_stocks_df.index.normalize().unique()\n",
    "\n",
    "    def assign_trading_day(date):\n",
    "        if pd.isnull(date):\n",
    "            return None\n",
    "\n",
    "        ts_time = date.time()\n",
    "        ts_date = date.date()\n",
    "        day = pd.Timestamp(ts_date)\n",
    "\n",
    "        # During market hours: assign to that day if valid\n",
    "        if MARKET_OPEN <= ts_time <= MARKET_CLOSE:\n",
    "            return day if day in trading_days else None\n",
    "\n",
    "        # After market close: assign to next trading day\n",
    "        elif ts_time > MARKET_CLOSE:\n",
    "            next_day = day + pd.Timedelta(days=1)\n",
    "            while next_day not in trading_days:\n",
    "                next_day += pd.Timedelta(days=1)\n",
    "            return next_day\n",
    "\n",
    "        # Before market open: assign to same day if valid\n",
    "        else:\n",
    "            return day if day in trading_days else None\n",
    "\n",
    "    # Apply the function to assign trading day for each news date\n",
    "    news_df['trading_day'] = news_df['date'].apply(assign_trading_day)\n",
    "\n",
    "    # Drop rows where trading_day assignment failed\n",
    "    aligned_news = news_df.dropna(subset=['trading_day'])\n",
    "\n",
    "    return aligned_news\n",
    "\n",
    "# Example usage:\n",
    "# Make sure news_df and stock_df are defined and have proper datetime indices\n",
    "# For example:\n",
    "# news_df['date'] should be datetime64[ns]\n",
    "# stock_df.index should be datetime64[ns]\n",
    "\n",
    "aligned_news = align_news_with_stocks(news_df, combined_stocks_df)\n",
    "\n",
    "# Print info to verify\n",
    "print(aligned_news.columns)\n",
    "# aligned_news.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "962d16fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News shape: (1407328, 7)\n",
      "Stock shape: (45428, 9)\n",
      "Aligned News shape: (55230, 7)\n",
      "Missing in aligned_news:\n",
      "Unnamed: 0     0\n",
      "headline       0\n",
      "url            0\n",
      "publisher      0\n",
      "date           0\n",
      "stock          0\n",
      "trading_day    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"News shape:\", news_df.shape)\n",
    "print(\"Stock shape:\", combined_stocks_df.shape)\n",
    "print(\"Aligned News shape:\", aligned_news.shape)\n",
    "\n",
    "print(\"Missing in aligned_news:\")\n",
    "print(aligned_news.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aaa6bbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock',\n",
      "       'trading_day'],\n",
      "      dtype='object')\n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends',\n",
      "       'Stock Splits', 'Ticker'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock',\n",
      "       'trading_day'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(news_df.columns)\n",
    "print(combined_stocks_df.columns)\n",
    "print(aligned_news.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28a801f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
      "       'Dividends', 'Stock Splits', 'Ticker'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "combined_stocks_df = combined_stocks_df.reset_index()\n",
    "print(combined_stocks_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26fd0528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock',\n",
      "       'trading_day', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close',\n",
      "       'Volume', 'Dividends', 'Stock Splits', 'Ticker'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_18028\\3893708251.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  aligned_news['trading_day'] = pd.to_datetime(aligned_news['trading_day'])\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'trading_day' column in aligned news and stock_df['date'] exists\n",
    "aligned_news['trading_day'] = pd.to_datetime(aligned_news['trading_day'])\n",
    "combined_stocks_df['Date'] = pd.to_datetime(combined_stocks_df['Date'])  # or from index if needed\n",
    "\n",
    "# Merge on 'trading_day'\n",
    "merged_df = pd.merge(aligned_news, combined_stocks_df, left_on='trading_day', right_on='Date', how='inner')\n",
    "print(merged_df.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finance_week1)",
   "language": "python",
   "name": "finance_week1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
